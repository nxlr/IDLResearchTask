{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOSRft2mBj3fzBZzANBbv4P",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nxlr/IDLResearchTask/blob/main/Python_Sachin_Sharma.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "lEp69Xj8Zg4J",
        "outputId": "cb3743a2-76c9-49ff-afd7-f58c5e64c71f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "python-Levenshtein not found. Installing...\n"
          ]
        }
      ],
      "source": [
        "import subprocess\n",
        "import sys\n",
        "\n",
        "def install(package):\n",
        "    subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", package])\n",
        "\n",
        "# List of required packages\n",
        "required_packages = [\n",
        "    \"numpy\", \"pandas\", \"matplotlib\", \"fuzzywuzzy\", \"python-Levenshtein\", \"tqdm\" # Add your required packages here\n",
        "]\n",
        "\n",
        "for package in required_packages:\n",
        "    try:\n",
        "        __import__(package)\n",
        "    except ImportError:\n",
        "        print(f\"{package} not found. Installing...\")\n",
        "        install(package)\n",
        "\n",
        "\n",
        "# Import modules after they have been checked for installation\n",
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from fuzzywuzzy import fuzz\n",
        "from fuzzywuzzy import process\n",
        "from tqdm import tqdm"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the datasets\n",
        "foreign_names = pd.read_csv('/content/ForeignNames_2019_2020.csv')\n",
        "country_iso = pd.read_csv('/content/Country_Name_ISO3.csv')\n",
        "\n",
        "# Merge the datasets on the country name columns\n",
        "merged_data = pd.merge(foreign_names, country_iso, left_on='foreigncountry_cleaned', right_on='country_name', how='left')\n",
        "\n",
        "# Manually assign the ISO3 code and country name for \"South Korea\"\n",
        "merged_data.loc[merged_data['foreigncountry_cleaned'] == 'South Korea', 'country_iso3'] = 'KOR'\n",
        "merged_data.loc[merged_data['foreigncountry_cleaned'] == 'South Korea', 'country_name'] = 'South Korea'\n",
        "\n",
        "# Save the merged dataset for future use\n",
        "merged_data.to_csv('/content/merged_ForeignNames_2019_2020.csv', index=False)\n",
        "\n",
        "# print(merged_data.head())"
      ],
      "metadata": {
        "id": "5emraGNDbaAh"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the merged dataset\n",
        "merged_data = pd.read_csv('/content/merged_ForeignNames_2019_2020.csv')\n",
        "\n",
        "# Clean the firm names by lowercasing and stripping whitespace\n",
        "merged_data['cleaned_firm_name'] = merged_data['foreign'].str.lower().str.strip()\n",
        "\n",
        "# Convert all entries to strings and replace NaN values with an empty string\n",
        "merged_data['cleaned_firm_name'] = merged_data['cleaned_firm_name'].fillna('').astype(str)"
      ],
      "metadata": {
        "id": "47SyfqsWcL_I"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Group the data by country to perform matching within each country\n",
        "def standardize_names(group):\n",
        "    # Get unique firm names and filter out any empty strings\n",
        "    unique_names = [name for name in group['cleaned_firm_name'].unique() if name]\n",
        "\n",
        "    # Create a dictionary to store the best matches\n",
        "    best_match_dict = {}\n",
        "\n",
        "    # Iterate through each unique name\n",
        "    for name in unique_names:\n",
        "        # If name is already matched, skip it\n",
        "        if name in best_match_dict:\n",
        "            continue\n",
        "\n",
        "        # Find top 3 best matches for the name within the same group\n",
        "        matches = process.extract(name, unique_names, scorer=fuzz.token_sort_ratio, limit=3)\n",
        "\n",
        "        # Assign the best match name to all similar names\n",
        "        for match_name, score in matches:\n",
        "            if score > 85:  # Set a threshold for similarity\n",
        "                best_match_dict[match_name] = name\n",
        "\n",
        "    # Apply the best matches to the group\n",
        "    group['standardized_name'] = group['cleaned_firm_name'].map(best_match_dict)\n",
        "\n",
        "    return group\n",
        "\n",
        "# Process data in smaller chunks\n",
        "chunk_size = 5000  # Define a chunk size\n",
        "chunks = [merged_data[i:i + chunk_size] for i in range(0, merged_data.shape[0], chunk_size)]\n",
        "\n",
        "# Initialize an empty list to collect results\n",
        "standardized_chunks = []\n",
        "\n",
        "# Process each chunk individually with a progress bar\n",
        "for chunk in tqdm(chunks, desc=\"Processing Chunks\"):\n",
        "    standardized_chunk = chunk.groupby('foreigncountry_cleaned').apply(standardize_names)\n",
        "    standardized_chunks.append(standardized_chunk)\n",
        "\n",
        "# Combine all chunks into a single DataFrame\n",
        "standardized_data = pd.concat(standardized_chunks)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "pm2CSxGwdVrb",
        "outputId": "2461b17f-f84a-455e-8341-faf28670a218"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing Chunks: 100%|██████████| 125/125 [1:00:17<00:00, 28.94s/it]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Reset the index to remove ambiguity\n",
        "standardized_data = standardized_data.reset_index(drop=True)\n",
        "\n",
        "# Assign unique IDs based on the standardized names within each country\n",
        "standardized_data['cleaned_ID'] = standardized_data.groupby(['foreigncountry_cleaned', 'standardized_name']).ngroup().apply(lambda x: f\"{x+1:06}\")\n",
        "standardized_data['cleaned_ID'] = standardized_data['country_iso3'] + standardized_data['cleaned_ID']\n",
        "\n",
        "# Remove rows with NaN values in important columns\n",
        "standardized_data = standardized_data.dropna(subset=['foreign', 'standardized_name', 'cleaned_ID'])\n",
        "\n",
        "# Display the updated dataset\n",
        "print(standardized_data[['foreign', 'standardized_name', 'cleaned_ID']].head())\n",
        "\n",
        "# Save the standardized dataset to a CSV file\n",
        "standardized_data.to_csv('/content/outputfile_sachin_1.csv', index=False)\n",
        "\n",
        "# Create a file with only the firms whose names have changed\n",
        "changed_names = standardized_data[standardized_data['foreign'] != standardized_data['standardized_name']]\n",
        "\n",
        "# Remove rows with NaN values in the changed data\n",
        "changed_names = changed_names.dropna(subset=['foreign', 'standardized_name'])\n",
        "\n",
        "changed_names[['foreign', 'standardized_name', 'cleaned_ID']].to_csv('/content/outputfile_sachin_1_changed.csv', index=False)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cQ32oXYidhZy",
        "outputId": "3d0ca6e4-c687-4f76-f28d-245736b19c4d"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                       foreign            standardized_name cleaned_ID\n",
            "0                Inayat Sheraz                inayat sheraz  AFG000064\n",
            "1                 Ijaz Shakeel                 ijaz shakeel  AFG000059\n",
            "2                 Shahed Hakim                 shahed hakim  AFG000120\n",
            "3  Lg Electronics Algerie Sarl  lg electronics algerie sarl  DZA000341\n",
            "4         Toyota Argentina S A         toyota argentina s a  ARG001676\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(standardized_data.head())\n",
        "len(standardized_data)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "EwKnSKtnzxht",
        "outputId": "d978e329-4a12-484e-df49-5c6a19804af6"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                       foreign foreigncountry_cleaned  shpmtyear country_name  \\\n",
            "0                Inayat Sheraz            Afghanistan       2020  Afghanistan   \n",
            "1                 Ijaz Shakeel            Afghanistan       2020  Afghanistan   \n",
            "2                 Shahed Hakim            Afghanistan       2020  Afghanistan   \n",
            "4  Lg Electronics Algerie Sarl                Algeria       2020      Algeria   \n",
            "5         Toyota Argentina S A              Argentina       2020    Argentina   \n",
            "\n",
            "  country_iso3            cleaned_firm_name            standardized_name  \\\n",
            "0          AFG                inayat sheraz                inayat sheraz   \n",
            "1          AFG                 ijaz shakeel                 ijaz shakeel   \n",
            "2          AFG                 shahed hakim                 shahed hakim   \n",
            "4          DZA  lg electronics algerie sarl  lg electronics algerie sarl   \n",
            "5          ARG         toyota argentina s a         toyota argentina s a   \n",
            "\n",
            "  cleaned_ID  \n",
            "0  AFG0064.0  \n",
            "1  AFG0059.0  \n",
            "2  AFG0120.0  \n",
            "4  DZA0341.0  \n",
            "5  ARG1693.0  \n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "621437"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(changed_names[['foreign', 'standardized_name', 'cleaned_ID']].head())\n",
        "len(changed_names)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "ug8wkKio1rvP",
        "outputId": "53b491b9-8f1a-4194-dc00-28df6cd870d3"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                       foreign            standardized_name cleaned_ID\n",
            "0                Inayat Sheraz                inayat sheraz  AFG0064.0\n",
            "1                 Ijaz Shakeel                 ijaz shakeel  AFG0059.0\n",
            "2                 Shahed Hakim                 shahed hakim  AFG0120.0\n",
            "4  Lg Electronics Algerie Sarl  lg electronics algerie sarl  DZA0341.0\n",
            "5         Toyota Argentina S A         toyota argentina s a  ARG1693.0\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "621406"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "files.download('/content/outputfile_sachin_1.csv')\n",
        "files.download('/content/outputfile_sachin_1_changed.csv')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "AtCyUpkX4PyI",
        "outputId": "3a9251db-cf4e-4554-e870-7162be6a1da9"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_bc69f6b5-eb20-4898-8c58-99ff0bc45b8f\", \"outputfile_sachin_1.csv\", 67925719)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_848aa266-0022-438d-9aab-7eb4f06189a2\", \"outputfile_sachin_1_changed.csv\", 36294371)"
            ]
          },
          "metadata": {}
        }
      ]
    }
  ]
}